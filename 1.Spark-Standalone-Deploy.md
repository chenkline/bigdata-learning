# Spark Standalone 模式集群部署指南

# 集群节点规划

Master节点: 192.168.2.131
Worker节点：192.168.2.132、192.168.2.133、192.168.2.134

所有节点使用 CentOS 7.9.2009


# 部署步骤
## 1.下载安装包【仅Master主机】
首先在Master节点上下载JDK、Scala与Spark到用户目录下，Spark要求是带Hadoop的版本；
jdk-8u212-linux-x64.tar.gz,
scala-2.12.8.tgz,
Python-3.5.10.tar.xz
spark-2.4.7-bin-hadoop2.7.tgz

```
cd $HOME
wget https://www.python.org/ftp/python/3.5.10/Python-3.5.10.tar.xz
wget https://apache.osuosl.org/spark/spark-2.4.7/spark-2.4.7-bin-hadoop2.7.tgz
wget https://downloads.lightbend.com/scala/2.12.8/scala-2.12.8.tgz
```
登录Oracle网站，下载jdk-8u212-linux-x64.tar.gz，并传输到Master节点用户主目录
若使用其它JDK版本，请修改下文相关命令


## 2.设置SSH免登录【仅Master主机】
设置登录用户SSH免密登录，并在所有节点上创建spark用户，并设置spark用户也免密登录
```
ssh-keygen -t rsa -N ''
export NODES=(192.168.2.131 192.168.2.132 192.168.2.133 192.168.2.134)
for node in ${NODES[@]}
  do
    echo ">>> ${node}"
    ssh-copy-id $USER@${node}
  done
export NODES=(192.168.2.132 192.168.2.133 192.168.2.134)
for node in ${NODES[@]}
  do
    echo ">>> ${node}"
    scp ~/.ssh/{id_rsa,id_rsa.pub,known_hosts} $USER@${node}:/home/$USER/.ssh/
  done

export NODES=(192.168.2.131 192.168.2.132 192.168.2.133 192.168.2.134)
for node in ${NODES[@]}
  do
    echo ">>> ${node}"
    ssh $USER@${node} "sudo useradd spark && sudo cp -rf ~/.ssh /home/spark/ && sudo chown -R spark:spark /home/spark/.ssh"
  done
```

## 3.设置主机名
设置主机名【仅Master主机】
```
sudo hostnamectl set-hostname spark-master
export NODES=(spark-slave1 spark-slave2 spark-slave3)
for node in ${NODES[@]}
  do
    echo ">>> ${node}"
    ssh $USER@${node} "sudo hostnamectl set-hostname ${node}"
  done
```

设置主机hosts文件【所有节点】
sudo vi /etc/hosts 
添加如下内容：
```
192.168.2.131 spark-master
192.168.2.132 spark-slave1
192.168.2.133 spark-slave2
192.168.2.134 spark-slave3
```

## 4.部署程序包

### 4.1. 部署Master节点
```
    chmod a+r $HOME/{jdk-8u212-linux-x64.tar.gz,scala-2.12.8.tgz,spark-2.4.7-bin-hadoop2.7.tgz}
    sudo tar zxvf $HOME/jdk-8u212-linux-x64.tar.gz -C /opt/ > /dev/null && cd /opt && sudo ln -s jdk1.8.0_212 jdk
    sudo chown -R root:root /opt/jdk1.8.0_212
    sudo chmod -R a+r /opt/jdk1.8.0_212
    sudo find /opt/jdk1.8.0_212 -type d | xargs -i sudo chmod a+x {}

    sudo tar zxvf $HOME/scala-2.12.8.tgz -C /opt/ > /dev/null && cd /opt && sudo ln -s scala-2.12.8 scala
    sudo chown -R root:root /opt/scala-2.12.8
    sudo chmod -R a+r /opt/scala-2.12.8
    sudo find /opt/scala-2.12.8 -type d | xargs -i sudo chmod a+x {}

    sudo tar zxvf $HOME/spark-2.4.7-bin-hadoop2.7.tgz -C /opt/ > /dev/null && cd /opt && sudo ln -s spark-2.4.7-bin-hadoop2.7 spark

    cat > $HOME/jdk-scala-env.sh <<\EOF
    export JAVA_HOME=/opt/jdk
    export JAVA_BIN=$JAVA_HOME/bin
    export JAVA_LIB=$JAVA_HOME/lib
    export CLASSPATH=.:$JAVA_LIB/tools.jar:$JAVA_LIB/dt.jar
    export PATH=$JAVA_BIN:$PATH

    export SCALA_HOME=/opt/scala
    export SCALA_BIN=${SCALA_HOME}/bin
    export PATH=$PATH:$SCALA_BIN

    export SPARK_HOME=/opt/spark
    export PATH=$PATH:$SPARK_HOME/bin
    EOF

    sudo cp -f /opt/spark/conf/spark-env.sh.template $HOME/spark-env.sh
    cat >> $HOME/spark-env.sh <<\EOF
    . ${SPARK_CONF_DIR}/jdk-scala-env.sh
    echo JAVA_HOME:$JAVA_HOME
    EOF
    sudo chmod a+rx cp $HOME/{spark-env.sh,jdk-scala-env.sh}

    cat > /opt/spark/conf/slaves <<\EOF
    spark-slave1
    spark-slave2
    spark-slave3
    EOF
    cp $HOME/{spark-env.sh,jdk-scala-env.sh} /opt/spark/conf/
    sudo chown -R spark:spark /opt/spark-2.4.7-bin-hadoop2.7
    sudo chmod -R a+r /opt/spark-2.4.7-bin-hadoop2.7 
    sudo find /opt/spark-2.4.7-bin-hadoop2.7 -type d | xargs -i sudo chmod a+x {}

    sudo systemctl disable firewalld
    sudo systemctl stop firewalld
```

### 4.2. 部署Worker节点
```
export NODES=(spark-slave1 spark-slave2 spark-slave3)
for node in ${NODES[@]}
  do
    echo ">>> ${node}"
    scp $HOME/{spark-env.sh,jdk-scala-env.sh} $USER@${node}:$HOME/
    ssh $USER@${node} "chmod a+r $HOME/{spark-env.sh,jdk-scala-env.sh}"
    scp $HOME/{jdk-8u212-linux-x64.tar.gz,scala-2.12.8.tgz,spark-2.4.7-bin-hadoop2.7.tgz} $USER@${node}:$HOME/
    ssh $USER@${node} "chmod a+r $HOME/{jdk-8u212-linux-x64.tar.gz,scala-2.12.8.tgz,spark-2.4.7-bin-hadoop2.7.tgz}"

    ssh $USER@${node} "sudo tar zxvf $HOME/jdk-8u212-linux-x64.tar.gz -C /opt/ > /dev/null && cd /opt && sudo ln -s jdk1.8.0_212 jdk"
    ssh $USER@${node} "sudo chown -R root:root /opt/jdk1.8.0_212"
    ssh $USER@${node} "sudo chmod -R a+r /opt/jdk1.8.0_212"
    ssh $USER@${node} "sudo find /opt/jdk1.8.0_212 -type d | xargs -i sudo chmod a+x {}"

    ssh $USER@${node} "sudo tar zxvf $HOME/scala-2.12.8.tgz -C /opt/ > /dev/null && cd /opt && sudo ln -s scala-2.12.8 scala"
    ssh $USER@${node} "sudo chown -R root:root /opt/scala-2.12.8"
    ssh $USER@${node} "sudo chmod -R a+r /opt/scala-2.12.8"
    ssh $USER@${node} "sudo find /opt/scala-2.12.8 -type d | xargs -i sudo chmod a+x {}"

    ssh $USER@${node} "sudo tar zxvf $HOME/spark-2.4.7-bin-hadoop2.7.tgz -C /opt/ > /dev/null && cd /opt && sudo ln -s spark-2.4.7-bin-hadoop2.7 spark"
    ssh $USER@${node} "sudo cp -f $HOME/{spark-env.sh,jdk-scala-env.sh} /opt/spark/conf/"
    ssh $USER@${node} "sudo chown -R spark:spark /opt/spark-2.4.7-bin-hadoop2.7"
    ssh spark@${node} "chmod -R a+r /opt/spark-2.4.7-bin-hadoop2.7 && find /opt/spark-2.4.7-bin-hadoop2.7 -type d | xargs -i chmod a+x {}"

    ssh $USER@${node} "sudo systemctl disable firewalld"
    ssh $USER@${node} "sudo systemctl stop firewalld"

  done
```

### 5. 更换为使用Python3【可选】
注意更换为Python3时，一定要使用Python3.4.x 或者3.5.x版本，不能使用3.6+以上版本

#修改 spark-env.sh, 设置Python环境变量PYSPARK_PYTHON【仅Master节点】
```
    sudo cp -f /opt/spark/conf/spark-env.sh $HOME/spark-env.sh
    sudo cat >> $HOME/spark-env.sh <<\EOF
    export PYSPARK_PYTHON=/opt/Python3/bin/python3
    EOF
    sudo chmod a+rx cp $HOME/spark-env.sh
```

## 5.1. 部署Master节点
```
    chmod a+r $HOME/Python-3.5.10.tar.gz

    sudo tar zxvf $HOME/Python-3.5.10.tar.gz -C /opt/ > /dev/null && cd /opt && sudo ln -s Python-3.5.10 Python3
    sudo chown -R root:root /opt/Python-3.5.10
    sudo chmod -R a+r /opt/Python-3.5.10
    sudo find /opt/Python-3.5.10 -type d | xargs -i sudo chmod a+x {}

    sudo cp -f $HOME/spark-env.sh /opt/spark/conf/
    sudo chown spark:spark /opt/spark/conf/spark-env.sh
```

### 5.1. 部署Worker节点
```
export NODES=(spark-slave1 spark-slave2 spark-slave3)
for node in ${NODES[@]}
  do
    echo ">>> ${node}"

    scp $HOME/Python-3.5.10.tar.gz $USER@${node}:$HOME/
    ssh $USER@${node} "chmod a+r $HOME/Python-3.5.10.tar.gz"

    ssh $USER@${node} "sudo tar zxvf $HOME/Python-3.5.10.tar.gz -C /opt/ > /dev/null && cd /opt && sudo ln -s Python-3.5.10 Python3"
    ssh $USER@${node} "sudo chown -R root:root /opt/Python-3.5.10"
    ssh $USER@${node} "sudo chmod -R a+r /opt/Python-3.5.10"
    ssh $USER@${node} "sudo find /opt/Python-3.5.10 -type d | xargs -i sudo chmod a+x {}"

    scp $HOME/spark-env.sh $USER@${node}:$HOME/
    ssh $USER@${node} "sudo cp -f $HOME/spark-env.sh /opt/spark/conf/"
    ssh $USER@${node} "sudo chown spark:spark /opt/spark/conf/spark-env.sh"

  done
```

# 6. 启动停止spark集群【在Master节点操作】
注: 所有操作，先切换到spark用户执行
```sudo su - spark```

#启动spark集群
```/opt/spark/sbin/start-all.sh```

#停止spark集群
```/opt/spark/sbin/stop-all.sh```


# 7.运行Spark任务【在Master节点操作】

注: 所有操作，先切换到spark用户执行
```sudo su - spark```

#启动spark scala shell
```/opt/spark/bin/spark-shell --master spark://spark-master:7077```

#启动spark python shell
```/opt/spark/bin/pyspark --master spark://spark-master:7077```

#运行 JavaSparkPi 示例
```/opt/spark/bin/spark-submit --master spark://spark-master:7077 --jars examples/jars/scopt_2.11-3.7.0.jar --class org.apache.spark.examples.JavaSparkPi examples/jars/spark-examples_2.11-2.4.7.jar 10```

#运行 PythonPi 示例
```/opt/spark/bin/spark-submit --master spark://spark-master:7077 examples/src/main/python/pi.py 10```
